{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice with R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ISLR)\n",
    "attach(Auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling with different seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>324</li><li>167</li><li>129</li><li>299</li><li>270</li><li>187</li><li>307</li><li>85</li><li>277</li><li>362</li><li>330</li><li>263</li><li>329</li><li>79</li><li>213</li><li>37</li><li>105</li><li>217</li><li>366</li><li>165</li><li>290</li><li>383</li><li>89</li><li>289</li><li>340</li><li>326</li><li>382</li><li>42</li><li>111</li><li>20</li><li>44</li><li>343</li><li>70</li><li>121</li><li>40</li><li>172</li><li>25</li><li>248</li><li>198</li><li>39</li><li>298</li><li>280</li><li>160</li><li>14</li><li>130</li><li>45</li><li>22</li><li>206</li><li>230</li><li>193</li><li>104</li><li>367</li><li>255</li><li>341</li><li>342</li><li>103</li><li>331</li><li>13</li><li>296</li><li>375</li><li>176</li><li>279</li><li>110</li><li>84</li><li>29</li><li>141</li><li>252</li><li>221</li><li>108</li><li>304</li><li>33</li><li>347</li><li>149</li><li>287</li><li>102</li><li>145</li><li>118</li><li>323</li><li>107</li><li>64</li><li>224</li><li>337</li><li>51</li><li>325</li><li>372</li><li>138</li><li>390</li><li>389</li><li>282</li><li>143</li><li>285</li><li>170</li><li>48</li><li>204</li><li>295</li><li>24</li><li>181</li><li>214</li><li>225</li><li>163</li><li>43</li><li>1</li><li>328</li><li>78</li><li>284</li><li>116</li><li>233</li><li>61</li><li>86</li><li>374</li><li>49</li><li>242</li><li>246</li><li>247</li><li>239</li><li>219</li><li>135</li><li>364</li><li>363</li><li>310</li><li>53</li><li>348</li><li>65</li><li>376</li><li>124</li><li>77</li><li>218</li><li>98</li><li>194</li><li>19</li><li>31</li><li>174</li><li>237</li><li>75</li><li>16</li><li>358</li><li>9</li><li>50</li><li>92</li><li>122</li><li>152</li><li>386</li><li>207</li><li>244</li><li>229</li><li>350</li><li>355</li><li>391</li><li>223</li><li>373</li><li>309</li><li>140</li><li>126</li><li>349</li><li>344</li><li>319</li><li>258</li><li>15</li><li>271</li><li>388</li><li>195</li><li>201</li><li>318</li><li>17</li><li>212</li><li>127</li><li>133</li><li>41</li><li>384</li><li>392</li><li>159</li><li>117</li><li>72</li><li>36</li><li>315</li><li>294</li><li>157</li><li>378</li><li>313</li><li>306</li><li>272</li><li>106</li><li>185</li><li>88</li><li>281</li><li>228</li><li>238</li><li>368</li><li>80</li><li>30</li><li>93</li><li>234</li><li>220</li><li>240</li><li>369</li><li>164</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 324\n",
       "\\item 167\n",
       "\\item 129\n",
       "\\item 299\n",
       "\\item 270\n",
       "\\item 187\n",
       "\\item 307\n",
       "\\item 85\n",
       "\\item 277\n",
       "\\item 362\n",
       "\\item 330\n",
       "\\item 263\n",
       "\\item 329\n",
       "\\item 79\n",
       "\\item 213\n",
       "\\item 37\n",
       "\\item 105\n",
       "\\item 217\n",
       "\\item 366\n",
       "\\item 165\n",
       "\\item 290\n",
       "\\item 383\n",
       "\\item 89\n",
       "\\item 289\n",
       "\\item 340\n",
       "\\item 326\n",
       "\\item 382\n",
       "\\item 42\n",
       "\\item 111\n",
       "\\item 20\n",
       "\\item 44\n",
       "\\item 343\n",
       "\\item 70\n",
       "\\item 121\n",
       "\\item 40\n",
       "\\item 172\n",
       "\\item 25\n",
       "\\item 248\n",
       "\\item 198\n",
       "\\item 39\n",
       "\\item 298\n",
       "\\item 280\n",
       "\\item 160\n",
       "\\item 14\n",
       "\\item 130\n",
       "\\item 45\n",
       "\\item 22\n",
       "\\item 206\n",
       "\\item 230\n",
       "\\item 193\n",
       "\\item 104\n",
       "\\item 367\n",
       "\\item 255\n",
       "\\item 341\n",
       "\\item 342\n",
       "\\item 103\n",
       "\\item 331\n",
       "\\item 13\n",
       "\\item 296\n",
       "\\item 375\n",
       "\\item 176\n",
       "\\item 279\n",
       "\\item 110\n",
       "\\item 84\n",
       "\\item 29\n",
       "\\item 141\n",
       "\\item 252\n",
       "\\item 221\n",
       "\\item 108\n",
       "\\item 304\n",
       "\\item 33\n",
       "\\item 347\n",
       "\\item 149\n",
       "\\item 287\n",
       "\\item 102\n",
       "\\item 145\n",
       "\\item 118\n",
       "\\item 323\n",
       "\\item 107\n",
       "\\item 64\n",
       "\\item 224\n",
       "\\item 337\n",
       "\\item 51\n",
       "\\item 325\n",
       "\\item 372\n",
       "\\item 138\n",
       "\\item 390\n",
       "\\item 389\n",
       "\\item 282\n",
       "\\item 143\n",
       "\\item 285\n",
       "\\item 170\n",
       "\\item 48\n",
       "\\item 204\n",
       "\\item 295\n",
       "\\item 24\n",
       "\\item 181\n",
       "\\item 214\n",
       "\\item 225\n",
       "\\item 163\n",
       "\\item 43\n",
       "\\item 1\n",
       "\\item 328\n",
       "\\item 78\n",
       "\\item 284\n",
       "\\item 116\n",
       "\\item 233\n",
       "\\item 61\n",
       "\\item 86\n",
       "\\item 374\n",
       "\\item 49\n",
       "\\item 242\n",
       "\\item 246\n",
       "\\item 247\n",
       "\\item 239\n",
       "\\item 219\n",
       "\\item 135\n",
       "\\item 364\n",
       "\\item 363\n",
       "\\item 310\n",
       "\\item 53\n",
       "\\item 348\n",
       "\\item 65\n",
       "\\item 376\n",
       "\\item 124\n",
       "\\item 77\n",
       "\\item 218\n",
       "\\item 98\n",
       "\\item 194\n",
       "\\item 19\n",
       "\\item 31\n",
       "\\item 174\n",
       "\\item 237\n",
       "\\item 75\n",
       "\\item 16\n",
       "\\item 358\n",
       "\\item 9\n",
       "\\item 50\n",
       "\\item 92\n",
       "\\item 122\n",
       "\\item 152\n",
       "\\item 386\n",
       "\\item 207\n",
       "\\item 244\n",
       "\\item 229\n",
       "\\item 350\n",
       "\\item 355\n",
       "\\item 391\n",
       "\\item 223\n",
       "\\item 373\n",
       "\\item 309\n",
       "\\item 140\n",
       "\\item 126\n",
       "\\item 349\n",
       "\\item 344\n",
       "\\item 319\n",
       "\\item 258\n",
       "\\item 15\n",
       "\\item 271\n",
       "\\item 388\n",
       "\\item 195\n",
       "\\item 201\n",
       "\\item 318\n",
       "\\item 17\n",
       "\\item 212\n",
       "\\item 127\n",
       "\\item 133\n",
       "\\item 41\n",
       "\\item 384\n",
       "\\item 392\n",
       "\\item 159\n",
       "\\item 117\n",
       "\\item 72\n",
       "\\item 36\n",
       "\\item 315\n",
       "\\item 294\n",
       "\\item 157\n",
       "\\item 378\n",
       "\\item 313\n",
       "\\item 306\n",
       "\\item 272\n",
       "\\item 106\n",
       "\\item 185\n",
       "\\item 88\n",
       "\\item 281\n",
       "\\item 228\n",
       "\\item 238\n",
       "\\item 368\n",
       "\\item 80\n",
       "\\item 30\n",
       "\\item 93\n",
       "\\item 234\n",
       "\\item 220\n",
       "\\item 240\n",
       "\\item 369\n",
       "\\item 164\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 324\n",
       "2. 167\n",
       "3. 129\n",
       "4. 299\n",
       "5. 270\n",
       "6. 187\n",
       "7. 307\n",
       "8. 85\n",
       "9. 277\n",
       "10. 362\n",
       "11. 330\n",
       "12. 263\n",
       "13. 329\n",
       "14. 79\n",
       "15. 213\n",
       "16. 37\n",
       "17. 105\n",
       "18. 217\n",
       "19. 366\n",
       "20. 165\n",
       "21. 290\n",
       "22. 383\n",
       "23. 89\n",
       "24. 289\n",
       "25. 340\n",
       "26. 326\n",
       "27. 382\n",
       "28. 42\n",
       "29. 111\n",
       "30. 20\n",
       "31. 44\n",
       "32. 343\n",
       "33. 70\n",
       "34. 121\n",
       "35. 40\n",
       "36. 172\n",
       "37. 25\n",
       "38. 248\n",
       "39. 198\n",
       "40. 39\n",
       "41. 298\n",
       "42. 280\n",
       "43. 160\n",
       "44. 14\n",
       "45. 130\n",
       "46. 45\n",
       "47. 22\n",
       "48. 206\n",
       "49. 230\n",
       "50. 193\n",
       "51. 104\n",
       "52. 367\n",
       "53. 255\n",
       "54. 341\n",
       "55. 342\n",
       "56. 103\n",
       "57. 331\n",
       "58. 13\n",
       "59. 296\n",
       "60. 375\n",
       "61. 176\n",
       "62. 279\n",
       "63. 110\n",
       "64. 84\n",
       "65. 29\n",
       "66. 141\n",
       "67. 252\n",
       "68. 221\n",
       "69. 108\n",
       "70. 304\n",
       "71. 33\n",
       "72. 347\n",
       "73. 149\n",
       "74. 287\n",
       "75. 102\n",
       "76. 145\n",
       "77. 118\n",
       "78. 323\n",
       "79. 107\n",
       "80. 64\n",
       "81. 224\n",
       "82. 337\n",
       "83. 51\n",
       "84. 325\n",
       "85. 372\n",
       "86. 138\n",
       "87. 390\n",
       "88. 389\n",
       "89. 282\n",
       "90. 143\n",
       "91. 285\n",
       "92. 170\n",
       "93. 48\n",
       "94. 204\n",
       "95. 295\n",
       "96. 24\n",
       "97. 181\n",
       "98. 214\n",
       "99. 225\n",
       "100. 163\n",
       "101. 43\n",
       "102. 1\n",
       "103. 328\n",
       "104. 78\n",
       "105. 284\n",
       "106. 116\n",
       "107. 233\n",
       "108. 61\n",
       "109. 86\n",
       "110. 374\n",
       "111. 49\n",
       "112. 242\n",
       "113. 246\n",
       "114. 247\n",
       "115. 239\n",
       "116. 219\n",
       "117. 135\n",
       "118. 364\n",
       "119. 363\n",
       "120. 310\n",
       "121. 53\n",
       "122. 348\n",
       "123. 65\n",
       "124. 376\n",
       "125. 124\n",
       "126. 77\n",
       "127. 218\n",
       "128. 98\n",
       "129. 194\n",
       "130. 19\n",
       "131. 31\n",
       "132. 174\n",
       "133. 237\n",
       "134. 75\n",
       "135. 16\n",
       "136. 358\n",
       "137. 9\n",
       "138. 50\n",
       "139. 92\n",
       "140. 122\n",
       "141. 152\n",
       "142. 386\n",
       "143. 207\n",
       "144. 244\n",
       "145. 229\n",
       "146. 350\n",
       "147. 355\n",
       "148. 391\n",
       "149. 223\n",
       "150. 373\n",
       "151. 309\n",
       "152. 140\n",
       "153. 126\n",
       "154. 349\n",
       "155. 344\n",
       "156. 319\n",
       "157. 258\n",
       "158. 15\n",
       "159. 271\n",
       "160. 388\n",
       "161. 195\n",
       "162. 201\n",
       "163. 318\n",
       "164. 17\n",
       "165. 212\n",
       "166. 127\n",
       "167. 133\n",
       "168. 41\n",
       "169. 384\n",
       "170. 392\n",
       "171. 159\n",
       "172. 117\n",
       "173. 72\n",
       "174. 36\n",
       "175. 315\n",
       "176. 294\n",
       "177. 157\n",
       "178. 378\n",
       "179. 313\n",
       "180. 306\n",
       "181. 272\n",
       "182. 106\n",
       "183. 185\n",
       "184. 88\n",
       "185. 281\n",
       "186. 228\n",
       "187. 238\n",
       "188. 368\n",
       "189. 80\n",
       "190. 30\n",
       "191. 93\n",
       "192. 234\n",
       "193. 220\n",
       "194. 240\n",
       "195. 369\n",
       "196. 164\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  [1] 324 167 129 299 270 187 307  85 277 362 330 263 329  79 213  37 105 217\n",
       " [19] 366 165 290 383  89 289 340 326 382  42 111  20  44 343  70 121  40 172\n",
       " [37]  25 248 198  39 298 280 160  14 130  45  22 206 230 193 104 367 255 341\n",
       " [55] 342 103 331  13 296 375 176 279 110  84  29 141 252 221 108 304  33 347\n",
       " [73] 149 287 102 145 118 323 107  64 224 337  51 325 372 138 390 389 282 143\n",
       " [91] 285 170  48 204 295  24 181 214 225 163  43   1 328  78 284 116 233  61\n",
       "[109]  86 374  49 242 246 247 239 219 135 364 363 310  53 348  65 376 124  77\n",
       "[127] 218  98 194  19  31 174 237  75  16 358   9  50  92 122 152 386 207 244\n",
       "[145] 229 350 355 391 223 373 309 140 126 349 344 319 258  15 271 388 195 201\n",
       "[163] 318  17 212 127 133  41 384 392 159 117  72  36 315 294 157 378 313 306\n",
       "[181] 272 106 185  88 281 228 238 368  80  30  93 234 220 240 369 164"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the random seed with a constant to stabilize results of random processes:\n",
    "set.seed (1)\n",
    "\n",
    "# Generate random train indices:\n",
    "(train = sample(392, 196))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "23.2660086465003"
      ],
      "text/latex": [
       "23.2660086465003"
      ],
      "text/markdown": [
       "23.2660086465003"
      ],
      "text/plain": [
       "[1] 23.26601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit a linear regression model with horsepower to predict mpg on train set:\n",
    "lm.fit=lm(mpg~horsepower,data=Auto,subset=train)\n",
    "\n",
    "# mean((mpg-predict(lm.fit2,Auto))[-train]~2) # ---> This line used wrong syntax to calculate Test MSE.\n",
    "\n",
    "# Instead, we use the following line to calculate MSE of our model on test set:\n",
    "mean((mpg - predict(lm.fit,Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "18.7164594933828"
      ],
      "text/latex": [
       "18.7164594933828"
      ],
      "text/markdown": [
       "18.7164594933828"
      ],
      "text/plain": [
       "[1] 18.71646"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit a 2nd degree polynomial regression model with horsepower to predict mpg on train set:\n",
    "lm.fit2 = lm(mpg~poly(horsepower, 2) ,data=Auto,subset = train)\n",
    "\n",
    "# Calculate MSE on test set:\n",
    "mean((mpg - predict(lm.fit2,Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "18.7940067973945"
      ],
      "text/latex": [
       "18.7940067973945"
      ],
      "text/markdown": [
       "18.7940067973945"
      ],
      "text/plain": [
       "[1] 18.79401"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit a 3rd degree polynomial regression model with horsepower to predict mpg on train set:\n",
    "lm.fit3 = lm(mpg~poly(horsepower, 3) ,data=Auto,subset = train)\n",
    "\n",
    "# Calculate MSE on test set:\n",
    "mean((mpg - predict(lm.fit3,Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat above steps with another seed value:\n",
    "set.seed(2)\n",
    "train = sample(392 ,196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "25.7265106448139"
      ],
      "text/latex": [
       "25.7265106448139"
      ],
      "text/markdown": [
       "25.7265106448139"
      ],
      "text/plain": [
       "[1] 25.72651"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit a linear regression model with horsepower to predict mpg on train set:\n",
    "lm.fit=lm(mpg~horsepower,data=Auto,subset=train)\n",
    "\n",
    "# Calculate MSE on test set:\n",
    "mean((mpg - predict(lm.fit,Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "20.4303642741463"
      ],
      "text/latex": [
       "20.4303642741463"
      ],
      "text/markdown": [
       "20.4303642741463"
      ],
      "text/plain": [
       "[1] 20.43036"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit a 2nd degree polynomial regression model with horsepower to predict mpg on train set:\n",
    "lm.fit2 = lm(mpg~poly(horsepower, 2) ,data=Auto,subset = train)\n",
    "\n",
    "# Calculate MSE on test set:\n",
    "mean((mpg - predict(lm.fit2,Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "20.3853268638776"
      ],
      "text/latex": [
       "20.3853268638776"
      ],
      "text/markdown": [
       "20.3853268638776"
      ],
      "text/plain": [
       "[1] 20.38533"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit a 3rd degree polynomial regression model with horsepower to predict mpg on train set:\n",
    "lm.fit3 = lm(mpg~poly(horsepower, 3) ,data=Auto,subset = train)\n",
    "\n",
    "# Calculate MSE on test set:\n",
    "mean((mpg - predict(lm.fit3,Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-One-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>(Intercept)</dt><dd>39.9358610211705</dd><dt>horsepower</dt><dd>-0.157844733353654</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 39.9358610211705\n",
       "\\item[horsepower] -0.157844733353654\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   39.9358610211705horsepower\n",
       ":   -0.157844733353654\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 39.9358610  -0.1578447 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit a generalized linear model, which in this case is the same as fitting a linear regression model (lm.fit),\n",
    "# on horsepower to predict mpg\n",
    "glm.fit = glm(mpg~horsepower ,data= Auto)\n",
    "coef(glm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>(Intercept)</dt><dd>39.9358610211705</dd><dt>horsepower</dt><dd>-0.157844733353654</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 39.9358610211705\n",
       "\\item[horsepower] -0.157844733353654\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   39.9358610211705horsepower\n",
       ":   -0.157844733353654\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 39.9358610  -0.1578447 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit a linear regression model on horsepower to predict mpg\n",
    "lm.fit=lm(mpg~horsepower,data=Auto)\n",
    "coef(lm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>24.2315135179293</li><li>24.2311440937562</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24.2315135179293\n",
       "\\item 24.2311440937562\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24.2315135179293\n",
       "2. 24.2311440937562\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 24.23151 24.23114"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import boot library whicn contains cross-validation functions\n",
    "library(boot)\n",
    "\n",
    "# Fit a linear regression model on horsepower with glm.fit:\n",
    "glm.fit = glm(mpg~horsepower ,data= Auto)\n",
    "\n",
    "# Evaluate the model with K-Fold Cross-Validation:\n",
    "cv.err = cv.glm(Auto, glm.fit)\n",
    "# K isn't given, so cv.glm will use the default value of K, which is equal to the number of observations.\n",
    "# When K is equal to the number of observations, K-Fold Cross-Validation becomes Leave-One-Out Cross-Validation\n",
    "\n",
    "cv.err[['delta']]\n",
    "# Delta is a vector of length two. \n",
    "# The first component is the raw cross-validation estimate of prediction error. \n",
    "# The second component is the adjusted cross-validation estimate.\n",
    "# The adjustment is designed to compensate for the bias introduced by not using leave-one-out cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>24.2315135179292</li><li>19.2482131244897</li><li>19.3349840640291</li><li>19.4244303104303</li><li>19.0332138547041</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24.2315135179292\n",
       "\\item 19.2482131244897\n",
       "\\item 19.3349840640291\n",
       "\\item 19.4244303104303\n",
       "\\item 19.0332138547041\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24.2315135179292\n",
       "2. 19.2482131244897\n",
       "3. 19.3349840640291\n",
       "4. 19.4244303104303\n",
       "5. 19.0332138547041\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 24.23151 19.24821 19.33498 19.42443 19.03321"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a vector of zeros with length 5:\n",
    "cv.error = rep(0,5)\n",
    "\n",
    "# Evaluate 5 polynomial regression models of 5 different degrees from 1st to 5th with Leave-One-Out Cross-Validation:\n",
    "for (i in 1:5){\n",
    "    # Fit polynomial model of ith degree on horsepower to predict mpg:\n",
    "    glm.fit=glm(mpg~poly(horsepower,i),data=Auto)\n",
    "    # Calculate Leave-One-Out Cross-Validation error of ith model:\n",
    "    cv.error[i] = cv.glm(Auto,glm.fit)$delta[1]\n",
    "}\n",
    "cv.error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>24.2720671232254</li><li>19.2690928085129</li><li>19.3480535605547</li><li>19.2949648229745</li><li>19.0319790002896</li><li>18.8978121056401</li><li>19.1206066690695</li><li>19.1466631054789</li><li>18.8701307442148</li><li>20.9552042280369</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24.2720671232254\n",
       "\\item 19.2690928085129\n",
       "\\item 19.3480535605547\n",
       "\\item 19.2949648229745\n",
       "\\item 19.0319790002896\n",
       "\\item 18.8978121056401\n",
       "\\item 19.1206066690695\n",
       "\\item 19.1466631054789\n",
       "\\item 18.8701307442148\n",
       "\\item 20.9552042280369\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24.2720671232254\n",
       "2. 19.2690928085129\n",
       "3. 19.3480535605547\n",
       "4. 19.2949648229745\n",
       "5. 19.0319790002896\n",
       "6. 18.8978121056401\n",
       "7. 19.1206066690695\n",
       "8. 19.1466631054789\n",
       "9. 18.8701307442148\n",
       "10. 20.9552042280369\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 24.27207 19.26909 19.34805 19.29496 19.03198 18.89781 19.12061 19.14666\n",
       " [9] 18.87013 20.95520"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(17)\n",
    "# Create a vector of zeros with length 10:\n",
    "cv.error.10 = rep(0 ,10)\n",
    "\n",
    "# Evaluate 10 polynomial regression models of 10 different degrees from 1st to 10th with K-Fold Cross-Validation:\n",
    "for (i in 1:10) {\n",
    "    # Fit polynomial model of ith degree on horsepower to predict mpg:\n",
    "    glm.fit=glm(mpg~poly(horsepower,i),data=Auto)\n",
    "    # Calculate 10-Fold Cross-Validation error of ith model:\n",
    "    cv.error.10[i]=cv.glm(Auto, glm.fit, K=10)$delta[1]\n",
    "}\n",
    "cv.error.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bootstrap\n",
    "### Estimating the Accuracy of a Statistic of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to calculate the alpha value with the given formula, which is an estimation of investment risk:\n",
    "alpha.fn=function(data,index){\n",
    "  X=data$X[index]\n",
    "  Y=data$Y[index]\n",
    "  return((var(Y)-cov(X,Y))/(var(X)+var(Y)-2*cov(X,Y)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.57583207459283"
      ],
      "text/latex": [
       "0.57583207459283"
      ],
      "text/markdown": [
       "0.57583207459283"
      ],
      "text/plain": [
       "[1] 0.5758321"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate alpha for the first 100 observations:\n",
    "alpha.fn(Portfolio, 1:100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.736837501928544"
      ],
      "text/latex": [
       "0.736837501928544"
      ],
      "text/markdown": [
       "0.736837501928544"
      ],
      "text/plain": [
       "[1] 0.7368375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The next command uses the sample() function to randomly select\n",
    "# 100 observations from the range 1 to 100, with replacement.\n",
    "# This is equivalent to constructing a new bootstrap data set and\n",
    "# recomputing alpha based on the new data set.\n",
    "\n",
    "set.seed(1)\n",
    "alpha.fn(Portfolio, sample(100,100,replace=T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Portfolio, statistic = alpha.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "     original       bias    std. error\n",
       "t1* 0.5758321 -0.001695873  0.09366347"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Produce R=1000 bootstrap estimates for alpha using boot()\n",
    "boot(Portfolio, alpha.fn, R=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final output shows that using the original data, alpha = 0.5758,\n",
    "and that the bootstrap estimate for SE(a) is 0.0936"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Estimating the Accuracy of a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>(Intercept)</dt><dd>39.9358610211705</dd><dt>horsepower</dt><dd>-0.157844733353654</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 39.9358610211705\n",
       "\\item[horsepower] -0.157844733353654\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   39.9358610211705horsepower\n",
       ":   -0.157844733353654\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 39.9358610  -0.1578447 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit a linear regression model on a sample set with given index:\n",
    "boot.fn=function(data,index) {\n",
    "    return(coef(lm(mpg~horsepower,data=data,subset=index)))\n",
    "}\n",
    "boot.fn(Auto, 1:392)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>(Intercept)</dt><dd>40.3404516830189</dd><dt>horsepower</dt><dd>-0.163486837689938</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 40.3404516830189\n",
       "\\item[horsepower] -0.163486837689938\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   40.3404516830189horsepower\n",
       ":   -0.163486837689938\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 40.3404517  -0.1634868 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed (1)\n",
    "# Fit a linear regression model on a bootstrap sample:\n",
    "boot.fn(Auto,sample(392,392,replace=T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>(Intercept)</dt><dd>40.1186906449022</dd><dt>horsepower</dt><dd>-0.157706320543503</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 40.1186906449022\n",
       "\\item[horsepower] -0.157706320543503\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   40.1186906449022horsepower\n",
       ":   -0.157706320543503\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 40.1186906  -0.1577063 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit a linear regression model on another bootstrap sample:\n",
    "boot.fn(Auto,sample(392,392,replace=T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Auto, statistic = boot.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "      original        bias    std. error\n",
       "t1* 39.9358610  0.0544513229 0.841289790\n",
       "t2* -0.1578447 -0.0006170901 0.007343073"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Produce R=1000 bootstrap estimates for Linear Regression model using boot()\n",
    "boot(Auto,boot.fn,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 2 × 4 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th><th scope=col>t value</th><th scope=col>Pr(&gt;|t|)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>39.9358610</td><td>0.717498656</td><td> 55.65984</td><td>1.220362e-187</td></tr>\n",
       "\t<tr><th scope=row>horsepower</th><td>-0.1578447</td><td>0.006445501</td><td>-24.48914</td><td> 7.031989e-81</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 4 of type dbl\n",
       "\\begin{tabular}{r|llll}\n",
       "  & Estimate & Std. Error & t value & Pr(>\\textbar{}t\\textbar{})\\\\\n",
       "\\hline\n",
       "\t(Intercept) & 39.9358610 & 0.717498656 &  55.65984 & 1.220362e-187\\\\\n",
       "\thorsepower & -0.1578447 & 0.006445501 & -24.48914 &  7.031989e-81\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 4 of type dbl\n",
       "\n",
       "| <!--/--> | Estimate | Std. Error | t value | Pr(&gt;|t|) |\n",
       "|---|---|---|---|---|\n",
       "| (Intercept) | 39.9358610 | 0.717498656 |  55.65984 | 1.220362e-187 |\n",
       "| horsepower | -0.1578447 | 0.006445501 | -24.48914 |  7.031989e-81 |\n",
       "\n"
      ],
      "text/plain": [
       "            Estimate   Std. Error  t value   Pr(>|t|)     \n",
       "(Intercept) 39.9358610 0.717498656  55.65984 1.220362e-187\n",
       "horsepower  -0.1578447 0.006445501 -24.48914  7.031989e-81"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get summary of linear model coef:\n",
    "summary(lm(mpg~horsepower,data=Auto))$coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Auto, statistic = boot.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "        original        bias     std. error\n",
       "t1* 56.900099702  3.511640e-02 2.0300222526\n",
       "t2* -0.466189630 -7.080834e-04 0.0324241984\n",
       "t3*  0.001230536  2.840324e-06 0.0001172164"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Produce bootstrap estimation of 2nd degree polynomial regression model:\n",
    "boot.fn=function(data,index) {\n",
    "    coefficients(lm(mpg~horsepower+I(horsepower^2),data=data, subset = index))\n",
    "}\n",
    "set.seed(1)\n",
    "boot(Auto,boot.fn ,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "In Chapter 4, we used logisitc regression to predict the probability of “default” using “income” and “balance” on the “Default” data set. We will now estimate the test error of this logistic regression model using the validation set approach. Do not forget to set a random seed before beginning your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>default</th><th scope=col>student</th><th scope=col>balance</th><th scope=col>income</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>No</td><td>No </td><td> 729.5265</td><td>44361.625</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>No</td><td>Yes</td><td> 817.1804</td><td>12106.135</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>No</td><td>No </td><td>1073.5492</td><td>31767.139</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>No</td><td>No </td><td> 529.2506</td><td>35704.494</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>No</td><td>No </td><td> 785.6559</td><td>38463.496</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>No</td><td>Yes</td><td> 919.5885</td><td> 7491.559</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & default & student & balance & income\\\\\n",
       "  & <fct> & <fct> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & No & No  &  729.5265 & 44361.625\\\\\n",
       "\t2 & No & Yes &  817.1804 & 12106.135\\\\\n",
       "\t3 & No & No  & 1073.5492 & 31767.139\\\\\n",
       "\t4 & No & No  &  529.2506 & 35704.494\\\\\n",
       "\t5 & No & No  &  785.6559 & 38463.496\\\\\n",
       "\t6 & No & Yes &  919.5885 &  7491.559\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 4\n",
       "\n",
       "| <!--/--> | default &lt;fct&gt; | student &lt;fct&gt; | balance &lt;dbl&gt; | income &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | No | No  |  729.5265 | 44361.625 |\n",
       "| 2 | No | Yes |  817.1804 | 12106.135 |\n",
       "| 3 | No | No  | 1073.5492 | 31767.139 |\n",
       "| 4 | No | No  |  529.2506 | 35704.494 |\n",
       "| 5 | No | No  |  785.6559 | 38463.496 |\n",
       "| 6 | No | Yes |  919.5885 |  7491.559 |\n",
       "\n"
      ],
      "text/plain": [
       "  default student balance   income   \n",
       "1 No      No       729.5265 44361.625\n",
       "2 No      Yes      817.1804 12106.135\n",
       "3 No      No      1073.5492 31767.139\n",
       "4 No      No       529.2506 35704.494\n",
       "5 No      No       785.6559 38463.496\n",
       "6 No      Yes      919.5885  7491.559"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(ISLR)\n",
    "attach(Default)\n",
    "set.seed(1)\n",
    "head(Default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (a)\n",
    "Fit a logistic regression model that uses “income” and “balance” to predict “default”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = default ~ income + balance, family = \"binomial\", \n",
       "    data = Default)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.4725  -0.1444  -0.0574  -0.0211   3.7245  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept) -1.154e+01  4.348e-01 -26.545  < 2e-16 ***\n",
       "income       2.081e-05  4.985e-06   4.174 2.99e-05 ***\n",
       "balance      5.647e-03  2.274e-04  24.836  < 2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 2920.6  on 9999  degrees of freedom\n",
       "Residual deviance: 1579.0  on 9997  degrees of freedom\n",
       "AIC: 1585\n",
       "\n",
       "Number of Fisher Scoring iterations: 8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit.glm = glm(default ~ income + balance, data = Default, family = \"binomial\")\n",
    "summary(fit.glm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "Both income and balance are statistical signifincant (p-value < 0.05) in estimating default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (b)\n",
    "Using the validation set approach, estimate the test error of this model. In order to do this, you must perform the following steps:\n",
    "\n",
    "### I. Split the sample set into a training set and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sample(dim(Default)[1], dim(Default)[1] / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Fit a multiple logistic regression model using only the training observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = default ~ income + balance, family = \"binomial\", \n",
       "    data = Default, subset = train)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.5830  -0.1428  -0.0573  -0.0213   3.3395  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept) -1.194e+01  6.178e-01 -19.333  < 2e-16 ***\n",
       "income       3.262e-05  7.024e-06   4.644 3.41e-06 ***\n",
       "balance      5.689e-03  3.158e-04  18.014  < 2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 1523.8  on 4999  degrees of freedom\n",
       "Residual deviance:  803.3  on 4997  degrees of freedom\n",
       "AIC: 809.3\n",
       "\n",
       "Number of Fisher Scoring iterations: 8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit.glm = glm(default ~ income + balance, data = Default, family = \"binomial\", subset = train)\n",
    "summary(fit.glm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of default for that individual, and classifying the individual to the “default” category if the posterior probability is greater than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        \n",
       "pred.glm   No  Yes\n",
       "     No  4824  108\n",
       "     Yes   19   49"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probs = predict(fit.glm, newdata = Default[-train, ], type = \"response\")\n",
    "pred.glm = rep(\"No\", length(probs))\n",
    "pred.glm[probs > 0.5] = \"Yes\"\n",
    "table(pred.glm, default[-train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0254"
      ],
      "text/latex": [
       "0.0254"
      ],
      "text/markdown": [
       "0.0254"
      ],
      "text/plain": [
       "[1] 0.0254"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(pred.glm != default[-train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    " \n",
    "2.86% test error rate with the validation set approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (c)\n",
    "Repeat the process in (b) three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.0274\n",
      "[1] 0.0244\n",
      "[1] 0.0244\n"
     ]
    }
   ],
   "source": [
    "for (i in 1:3) {\n",
    "    train = sample(dim(Default)[1], dim(Default)[1] / 2)\n",
    "    fit.glm = glm(default ~ income + balance, data = Default, family = \"binomial\", subset = train)\n",
    "    probs = predict(fit.glm, newdata = Default[-train, ], type = \"response\")\n",
    "    pred.glm = rep(\"No\", length(probs))\n",
    "    pred.glm[probs > 0.5] = \"Yes\"\n",
    "    print(mean(pred.glm != default[-train]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "The validation estimate of the test error rate can be variable, depending on precisely which observations are included in the training set and which observations are included in the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task (d)\n",
    "Now consider a logistic regression model that predicts the probability of “default” using “income”, “balance”, and a dummy variable for “student”. Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for “student” leads to a reduction in the test error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0278"
      ],
      "text/latex": [
       "0.0278"
      ],
      "text/markdown": [
       "0.0278"
      ],
      "text/plain": [
       "[1] 0.0278"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = sample(dim(Default)[1], dim(Default)[1] / 2)\n",
    "fit.glm = glm(default ~ income + balance + student, data = Default, family = \"binomial\", subset = train)\n",
    "pred.glm = rep(\"No\", length(probs))\n",
    "probs = predict(fit.glm, newdata = Default[-train, ], type = \"response\")\n",
    "pred.glm[probs > 0.5] = \"Yes\"\n",
    "mean(pred.glm != default[-train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "It doesn't seem that the student dummy variable can improve validation set estimate of the test error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "We continue to consider the use of a logistic regression model to predict the probability of “default” using “income” and “balance” on the “Default” data set. In particular, we will now computes estimates for the standard errors of the “income” and “balance” logistic regression coefficients in two different ways: \n",
    "- (1) using the bootstrap\n",
    "- (2) using the standard formula for computing the standard errors in the glm() function. Do not forget to set a random seed before beginning your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (a)\n",
    "Using the summary() and glm() functions, determine the estimated standard errors for the coefficients associated with “income” and “balance” in a multiple logistic regression model that uses both predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = default ~ income + balance, family = \"binomial\", \n",
       "    data = Default)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.4725  -0.1444  -0.0574  -0.0211   3.7245  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept) -1.154e+01  4.348e-01 -26.545  < 2e-16 ***\n",
       "income       2.081e-05  4.985e-06   4.174 2.99e-05 ***\n",
       "balance      5.647e-03  2.274e-04  24.836  < 2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 2920.6  on 9999  degrees of freedom\n",
       "Residual deviance: 1579.0  on 9997  degrees of freedom\n",
       "AIC: 1585\n",
       "\n",
       "Number of Fisher Scoring iterations: 8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit.glm = glm(default ~ income + balance, data = Default, family = \"binomial\")\n",
    "summary(fit.glm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "The glm() estimates of the standard errors for the coefficients β0, β1 and β2 are respectively $4.348*10^{-1}$, $4.985*10^{-6}$ and $2.274*10^{-4}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (b)\n",
    "Write a function, boot.fn(), that takes as input the “Default” data set as well as an index of the observations, and that outputs the coefficient estimates for “income” and “balance” in the multiple logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot.fn = function(data, index) {\n",
    "    return (coef(glm(default ~ income + balance, data = data, family = \"binomial\", subset = index)))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (c)\n",
    "Use the boot() function together with your boot.fn() function to estimate the standard errors of the logistic regression coefficients for “income” and “balance”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Default, statistic = boot.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "         original        bias     std. error\n",
       "t1* -1.154047e+01 -3.910447e-02 4.350746e-01\n",
       "t2*  2.080898e-05  1.635325e-07 4.845196e-06\n",
       "t3*  5.647103e-03  1.842153e-05 2.302679e-04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(boot)\n",
    "boot(Default, boot.fn, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "The bootstrap estimates of the standard errors for the coefficients β0, β1 and β2 are respectively $4.344*10^{-1}$, $4.866*10^{-6}$ and $2.298*10^{-4}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (d)\n",
    "Comment on the estimated standard errors obtained using the glm() function and using your bootstrap function.\n",
    "\n",
    "**Comment:**\n",
    "\n",
    "The estimated standard errors obtained by the two methods are pretty close."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
